{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch utility imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.utils import make_grid\n",
    "import cv2\n",
    "#neural net imports\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(num, num2='0'):\n",
    "    f = open('train/train_' + num + '_digits_'+ num2 + '.json')\n",
    "\n",
    "    data = json.load(f)\n",
    "\n",
    "    f.close()\n",
    "    data = np.asarray(data)\n",
    "  \n",
    "    return data\n",
    "\n",
    "def create_dataset():\n",
    "  res = np.array([])\n",
    "  target = np.array([[]])\n",
    "  for num in range(9):\n",
    "    img = cv2.imread('train/train_' + str(num) + '.jpg')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    src, _ = detect(img)\n",
    "    for i,v in enumerate(src):\n",
    "        data = read_data(str(num), str(i))\n",
    "        target = np.concatenate((target, data.reshape(-1, 81)), axis=None)\n",
    "\n",
    "        w = masked(img, v)\n",
    "        tmp = np.asarray(list(gen(w)))\n",
    "        if len(res) == 0:\n",
    "            res = tmp.reshape(len(tmp), -1)\n",
    "        else:\n",
    "            res = np.vstack((res, tmp.reshape(len(tmp), -1)))\n",
    "    \n",
    "    \n",
    "  return res, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import operator\n",
    "from skimage.segmentation import clear_border\n",
    "import torch\n",
    "import math\n",
    "from imutils.perspective import four_point_transform\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "'''We are getting numbers in this chank of code'''\n",
    "\n",
    "\n",
    "def mask_prediction(image):\n",
    "    imgRGB = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    imgGREY = cv.cvtColor(imgRGB, cv.COLOR_RGB2GRAY)\n",
    "    \n",
    "    #4 th seminar has a great potential to make a nice mask to distinguish sudoku\n",
    "    HLS = cv.cvtColor(imgRGB, cv.COLOR_RGB2HLS)\n",
    "    LIGHT = HLS[:, :, 1]\n",
    "    maskHLS = (LIGHT < 100)\n",
    "    maskINT = maskHLS.astype(np.uint8)\n",
    "    contours, useless_param = cv.findContours(maskINT, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE) \n",
    "    \n",
    "    contour_areas = [cv.contourArea(c) for c in contours] \n",
    "    \n",
    "    sort_areas_inds = sorted(range(len(contour_areas)), key = lambda k: contour_areas[k], reverse=True) \n",
    "    largest_contours=sort_areas_inds[:10]\n",
    "\n",
    "    \n",
    "    sudokus_contour=[]\n",
    "    zero_mask = np.zeros((imgGREY.shape[:2]), np.uint8)\n",
    "    for i in range(len(largest_contours)):\n",
    "        if (contour_areas[largest_contours[i]] > 0.5 * contour_areas[largest_contours[0]]) and (contour_areas[largest_contours[i]] > 550000) : #the second condition will find second sudoku if any\n",
    "            cv.drawContours(zero_mask, [contours[largest_contours[i]]], 0, (255,0,0), -2) #adding largest contours\n",
    "            sudokus_contour.append(contours[largest_contours[i]])\n",
    "    \n",
    "    mask = np.bool_(zero_mask)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def preProcess(img):\n",
    "    height, width = 3000, 3000\n",
    "    img = cv.resize(img, (width,height))\n",
    "    imgGray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    imgBlur = cv.GaussianBlur(imgGray, (5,5), 1)\n",
    "    imgThreshold = cv.adaptiveThreshold(imgBlur, 255, 1, 1, 11, 2)\n",
    "    contours, hieracrchy = cv.findContours(imgThreshold, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    # imgThreshold = cv.cvtColor(imgThreshold, cv.COLOR_BGR2RGB)\n",
    "    return imgThreshold, contours\n",
    "\n",
    "def reorder(myPoints):\n",
    "    myPoints = myPoints.reshape((4, 2))\n",
    "    myPointsNew = np.zeros((4, 1, 2), dtype = np.int32)\n",
    "    add = myPoints.sum(1)\n",
    "    myPointsNew[0] = myPoints[np.argmin(add)]\n",
    "    myPointsNew[3] = myPoints[np.argmax(add)]\n",
    "    diff = np.diff(myPoints, axis = 1)\n",
    "    myPointsNew[1] = myPoints[np.argmin(diff)]\n",
    "    myPointsNew[2] = myPoints[np.argmax(diff)]\n",
    "    return myPointsNew\n",
    "\n",
    "def biggestContour(img, contours):\n",
    "    biggest = np.array([])\n",
    "    height, width = 3000, 3000\n",
    "    img = cv.resize(img, (width,height))\n",
    "    max_area = 0\n",
    "    for i in contours:\n",
    "        area = cv.contourArea(i)\n",
    "        if area > 50:\n",
    "            peri = cv.arcLength(i, True)\n",
    "            approx = cv.approxPolyDP(i, 0.02*peri, True)\n",
    "            if area > max_area and len(approx) == 4:\n",
    "                biggest = approx\n",
    "                max_area = area\n",
    "    if biggest.size != 0:\n",
    "            biggest = reorder(biggest)\n",
    "            pts1 = np.float32(biggest)\n",
    "            pts2 = np.float32([[0, 0], [img.shape[1], 0], [0, img.shape[1]], [img.shape[1], img.shape[0]]])\n",
    "            matrix = cv.getPerspectiveTransform(pts1, pts2)\n",
    "            imgWarpColored = cv.warpPerspective(img, matrix, (img.shape[1], img.shape[0]))\n",
    "            imgBlank = np.zeros((450, 450, 3), np.uint8)\n",
    "            imgWarpColored = cv.cvtColor(imgWarpColored, cv.COLOR_RGB2GRAY)\n",
    "    return biggest, max_area, imgWarpColored\n",
    "\n",
    "def splitBoxes_1 (img):\n",
    "    img = cv.resize(img, (450,450))\n",
    "    rows = np.vsplit(img, 9)\n",
    "    boxes = []\n",
    "    for r in rows:\n",
    "        cols = np.hsplit(r, 9)\n",
    "        for box in cols:\n",
    "            boxes.append(box)\n",
    "    return boxes\n",
    "\n",
    "def get_cropped(sudokus_cont, image_grey): #returns arrray of sudoku fields from image\n",
    "    sudokus=[] #list of images corresponding to cropped sudokus\n",
    "    for i in sudokus_cont:\n",
    "        #print(i)\n",
    "        epsilon = 0.1* cv.arcLength(i, True)\n",
    "        approx = cv.approxPolyDP(i, epsilon, True)\n",
    "        #print(approx)\n",
    "        #print(np.ravel(approx).shape)\n",
    "        #print(type(approx))\n",
    "        cropped_sudoku= four_point_transform(image_grey, np.ravel(approx).reshape(4,2))\n",
    "        sudokus.append(cropped_sudoku)\n",
    "    return sudokus\n",
    "\n",
    "\n",
    "def splitBoxes_2 (img):\n",
    "    for pieces in img:\n",
    "        pieces = cv.resize(pieces, (450,450))\n",
    "        rows = np.vsplit(pieces, 9)\n",
    "        boxes = []\n",
    "        for r in rows:\n",
    "            cols = np.hsplit(r, 9)\n",
    "            for box in cols:\n",
    "                boxes.append(box)\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def intializePredictionModel():\n",
    "    model = load_model('myModel.h5')\n",
    "    return model\n",
    "\n",
    "\n",
    "def getPrediction (boxes):\n",
    "    model = intializePredictionModel()\n",
    "    result = []\n",
    "    for image in boxes:\n",
    "        #Image preparation\n",
    "        img = np.asarray(image)\n",
    "        img = img[4:img.shape[0] - 4, 4:img.shape[1] - 4]\n",
    "        img = cv.resize(img, (28,28))\n",
    "        img = img / 255\n",
    "        img = img.reshape(1, 28, 28, 1)\n",
    "        #Predict\n",
    "        predictions = model.predict(img)\n",
    "        #classIndex = model.predict_classes(img)\n",
    "        classIndex = np.argmax(predictions, axis = -1)\n",
    "        probabilityValue = np.amax(predictions)\n",
    "        #print(classIndex, probabilityValue)\n",
    "        #Saving\n",
    "        if probabilityValue > 0.8:\n",
    "            result.append(classIndex[0])\n",
    "        else:\n",
    "            result.append(-1)\n",
    "    boards = np.array(result)\n",
    "    boards = np.reshape(boards, (9,9))\n",
    "    boards = [np.int16(boards)]\n",
    "    return boards, result\n",
    "\n",
    "def predict_image(img):\n",
    "    mask = mask_prediction(img)\n",
    "    imgThreshold, contours = preProcess(img)\n",
    "    biggest, max_area, imgWarpColored = biggestContour(img, contours)\n",
    "    boxes = splitBoxes_1 (imgWarpColored)\n",
    "    # sudokus = get_cropped(sudokus_cont, img_grey)\n",
    "    # boxes = splitBoxes_2 (sudokus)\n",
    "    digits, result = getPrediction (boxes)\n",
    "    return mask, digits\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a804bd019268a41cbbeeef860d147e16c974ce185fe2160f47e73932cd250b6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
